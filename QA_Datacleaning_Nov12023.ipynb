{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ced0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install spacy\n",
    "pip install textblob\n",
    "pip install autocorrect\n",
    "pip install pyspellchecker\n",
    "pip install spellchecker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfd51a",
   "metadata": {},
   "source": [
    "# spellcheck_with five libraries for both Q and As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecf1ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from autocorrect import Speller\n",
    "from textblob import TextBlob\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "from spellchecker.spellchecker import SpellChecker as SpellChecker2\n",
    "\n",
    "\n",
    "\n",
    "def spellcheck_with_spacy(df):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    spell = Speller(lang='en')\n",
    "\n",
    "    def clean_and_spellcheck(text):\n",
    "        doc = nlp(str(text))  # Convert to string to handle non-string values\n",
    "        corrected_words = [spell(token.lemma_) for token in doc]\n",
    "        return ' '.join(corrected_words)\n",
    "\n",
    "    df['Question'] = df['Question'].apply(clean_and_spellcheck)\n",
    "    df['Answer'] = df['Answer'].apply(clean_and_spellcheck)\n",
    "    return df\n",
    "\n",
    "def spellcheck_with_textblob(df):\n",
    "    def clean_and_spellcheck(text):\n",
    "        blob = TextBlob(text)\n",
    "        corrected_text = str(blob.correct())\n",
    "        return corrected_text\n",
    "\n",
    "    df['Question'] = df['Question'].apply(clean_and_spellcheck)\n",
    "    df['Answer'] = df['Answer'].apply(clean_and_spellcheck)\n",
    "    return df\n",
    "\n",
    "def spellcheck_with_autocorrect(df):\n",
    "    spell = Speller(lang='en')\n",
    "\n",
    "    def clean_and_spellcheck(text):\n",
    "        corrected_text = spell(text)\n",
    "        return corrected_text\n",
    "\n",
    "    df['Question'] = df['Question'].astype(str).apply(clean_and_spellcheck)\n",
    "    df['Answer'] = df['Answer'].astype(str).apply(clean_and_spellcheck)\n",
    "    return df\n",
    "\n",
    "def spellcheck_with_pyspellchecker(df):\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    def clean_and_spellcheck(text):\n",
    "        words = text.split()\n",
    "        corrected_words = [spell.correction(word) if spell.correction(word) is not None else word for word in words]\n",
    "        return ' '.join(corrected_words)\n",
    "\n",
    "    df['Question'] = df['Question'].astype(str).apply(clean_and_spellcheck)\n",
    "    df['Answer'] = df['Answer'].astype(str).apply(clean_and_spellcheck)\n",
    "    return df\n",
    "\n",
    "def spellcheck_with_spellchecker(df):\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    def clean_and_spellcheck(text):\n",
    "        words = text.split()\n",
    "        corrected_words = [spell.correction(word) if spell.correction(word) is not None else word for word in words]\n",
    "        return ' '.join(corrected_words)\n",
    "\n",
    "    df['Question'] = df['Question'].astype(str).apply(clean_and_spellcheck)\n",
    "    df['Answer'] = df['Answer'].astype(str).apply(clean_and_spellcheck)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Load \n",
    "    df = pd.read_csv('db8606_20.csv')\n",
    " \n",
    "   \n",
    "     # Spell-check using Spacy for lemmatization and autocorrection\n",
    "    df = spellcheck_with_spacy(df)\n",
    "\n",
    "    # Spell-check using TextBlob\n",
    "    df = spellcheck_with_textblob(df)\n",
    "\n",
    "    # Spell-check using Autocorrect\n",
    "    df = spellcheck_with_autocorrect(df)\n",
    "\n",
    "    # Spell-check using Pyspellchecker\n",
    "    df = spellcheck_with_pyspellchecker(df)\n",
    "\n",
    "    # Spell-check using Spellchecker\n",
    "    df = spellcheck_with_spellchecker(df)\n",
    "\n",
    "    # Save the final cleaned dataset to a CSV file\n",
    "    df.to_csv('final_cleaned_dataset.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5efef",
   "metadata": {},
   "source": [
    "# add_full_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cf9242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two rows without full stops at the end of Answer column:\n",
      "    id                                           Question  \\\n",
      "0  180  how do China and India lead in greeting of the...   \n",
      "1  181  what be the main highlight of deutsche et al i...   \n",
      "\n",
      "                                              Answer           topic_name  \\\n",
      "0            Hi et al 2019 find that China and India      Climate Impacts   \n",
      "1  deutsche et al is 2008 study explore the impac...  Researching Ecology   \n",
      "\n",
      "                                         topic_words      Riya  \\n  \\\n",
      "0  climatological, climatic, climatology, climato...  analysis NaN   \n",
      "1  researching, research, researched, researches,...  analysis NaN   \n",
      "\n",
      "                         Lola     Suman   Narunja  Simon           Sapna  \n",
      "0  incomplete answer provided  analysis  analysis    NaN  Incomplete Q&A  \n",
      "1                    analysis  analysis  analysis    NaN        strategy  \n",
      "\n",
      "First two rows with full stops added at the end of Answer column:\n",
      "    id                                           Question  \\\n",
      "0  180  how do China and India lead in greeting of the...   \n",
      "1  181  what be the main highlight of deutsche et al i...   \n",
      "\n",
      "                                              Answer           topic_name  \\\n",
      "0           Hi et al 2019 find that China and India.      Climate Impacts   \n",
      "1  deutsche et al is 2008 study explore the impac...  Researching Ecology   \n",
      "\n",
      "                                         topic_words      Riya  \\n  \\\n",
      "0  climatological, climatic, climatology, climato...  analysis NaN   \n",
      "1  researching, research, researched, researches,...  analysis NaN   \n",
      "\n",
      "                         Lola     Suman   Narunja  Simon           Sapna  \n",
      "0  incomplete answer provided  analysis  analysis    NaN  Incomplete Q&A  \n",
      "1                    analysis  analysis  analysis    NaN        strategy  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_full_stops(df):\n",
    "    def check_full_stop(text):\n",
    "        if pd.notnull(text) and isinstance(text, str) and text.strip() and text.strip()[-1] != '.':\n",
    "            return text.strip() + '.'\n",
    "        else:\n",
    "            return text\n",
    "\n",
    "    # Filter and print the first two rows without full stops\n",
    "    rows_without_full_stops = df[df['Answer'].apply(lambda x: pd.notnull(x) and isinstance(x, str) and x.strip() and x.strip()[-1] != '.')].head(2)\n",
    "    print(\"First two rows without full stops at the end of Answer column:\")\n",
    "    print(rows_without_full_stops)\n",
    "\n",
    "    # Apply the function to add full stops\n",
    "    df['Answer'] = df['Answer'].apply(check_full_stop)\n",
    "\n",
    "    # Find and print the first two rows after adding full stops\n",
    "    rows_with_full_stops = df.head(2)\n",
    "    print(\"\\nFirst two rows with full stops added at the end of Answer column:\")\n",
    "    print(rows_with_full_stops)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load dataset into a DataFrame\n",
    "df = pd.read_csv('final_cleaned_dataset.csv')\n",
    "\n",
    "# Apply the function to add full stops and print rows as described\n",
    "df = add_full_stops(df)\n",
    "\n",
    "# Save the modified dataset to a new CSV file\n",
    "df.to_csv('dataset_with_full_stops.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a705bb2",
   "metadata": {},
   "source": [
    "# replace multiple commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cb653cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def replace_multiple_commas(df):\n",
    "    def replace_commas(text):\n",
    "        if isinstance(text, str):  # Check if the value is a string\n",
    "            # Replace multiple commas (with or without spaces) with a single comma\n",
    "            return re.sub(r',\\s*,', ', ', text)\n",
    "        return text  # Return non-string values as they are\n",
    "\n",
    "    df['Answer'] = df['Answer'].apply(replace_commas)\n",
    "    return df\n",
    "\n",
    "# Load dataset into a DataFrame\n",
    "df = pd.read_csv('dataset_with_full_stops.csv')\n",
    "\n",
    "# Apply the function to replace multiple commas in the 'Answer' column\n",
    "df = replace_multiple_commas(df)\n",
    "\n",
    "# Save the modified dataset to a new CSV file\n",
    "df.to_csv('dataset_with_single_commas.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7078594",
   "metadata": {},
   "source": [
    "# Capitalise first letter of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae122608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def correct_capitalization(df):\n",
    "    def capitalize_first_letter(text):\n",
    "        if isinstance(text, str):  # Check if the value is a string\n",
    "            # Check if the first character is lowercase\n",
    "            if text and text[0].islower():\n",
    "                return text[0].upper() + text[1:]  # Capitalize the first letter\n",
    "        return text  # Return non-string values as they are\n",
    "\n",
    "    df['Answer'] = df['Answer'].apply(capitalize_first_letter)\n",
    "    return df\n",
    "\n",
    "# Load dataset into a DataFrame\n",
    "df = pd.read_csv('dataset_with_single_commas.csv')\n",
    "\n",
    "# Apply the function to correct capitalization in the 'Answer' column\n",
    "df = correct_capitalization(df)\n",
    "\n",
    "# Save the modified dataset to a new CSV file\n",
    "df.to_csv('dataset_corrected_capitalization.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b39efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
